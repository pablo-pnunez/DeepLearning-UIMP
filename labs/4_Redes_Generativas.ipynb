{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD11kuoOXGuR"
      },
      "source": [
        "# Redes Generativas Adversarias (GAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además de los Autoencoders, otra de las arquitecturas más reconocidas para resolver problemas de aprendizaje no supervisado son las **Redes Generativas Adversarias (GAN)**.\n",
        "\n",
        "Las GANs fueron introducidas por Ian Goodfellow en 2014 y consisten en dos modelos que se entrenan simultáneamente: un **generador** y un **discriminador**. \n",
        "\n",
        "- El **generador** intenta crear datos falsos que sean indistinguibles de los datos reales a partir de, típicamente, un vector de ruido Gaussiano.\n",
        "- El **discriminador** intenta distinguir entre datos reales y falsos resolviendo un problema de clasificación binaria.\n",
        "\n",
        "El proceso de entrenamiento se denomina *\"adversario\"* puesto que el generador intenta engañar al discriminador, y el discriminador trata de no ser engañado.\n",
        "\n",
        "El objetivo del generador es maximizar la probabilidad de que el discriminador clasifique sus muestras generadas como reales. \n",
        "\n",
        "Por otro lado, el objetivo del discriminador es minimizar su tasa de error en la clasificación de las muestras reales y generadas.\n",
        "\n",
        "En esta práctica crearemos una **Deep Convolutional Generative Adversarial Network (DCGAN)** para generar nuevas imágenes de dígitos del conjunto *MNIST*.\n",
        "\n",
        "Ten en cuenta que, aunque sea su uso más común, no todas las GAN tienen por que ser convolucionales o generar imágenes, también pueden generar datos estructurados o tabulares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conjunto de datos\n",
        "\n",
        "Utilizaremos de nuevo el conjunto [MNIST](https://es.wikipedia.org/wiki/Base_de_datos_MNIST). Como recordarás, este conjunto posee imágenes en escala de grises con números del 0 al 9 escritos a mano por personas. Cada una de estas imágenes tiene una resolución de $28 \\times 28$ píxels. Al ser en escala de grises, cada imagen será un tensor de $1 \\times 28 \\times 28$.\n",
        "\n",
        "Este conjunto de datos está pensado para resolver un problema de *Aprendizaje supervisado de multiclasificación*, pero en este caso descartaremos las etiquetas y utilizaremos solamente las imágenes.\n",
        "\n",
        "De esta forma, nuestra red solo tendrá que aprender a generar imágenes de este dígito, y su tiempo de entrenamiento se reducirá considerablemente.\n",
        "\n",
        "### Descargar conjunto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Fijar la semilla para obtener reproducibilidad\n",
        "seed = 42\n",
        "keras.utils.set_random_seed(seed)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para simplificar el problema, nos quedaremos solamente con aquellas imágenes que tienen un dígito 8 o 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "six_idxs = [idx for idx, v in enumerate(y_train) if v == 8 or v == 3]\n",
        "x_train = x_train[six_idxs]\n",
        "y_train = y_train[six_idxs]\n",
        "\n",
        "# Mostramos la primera\n",
        "plt.imshow(x_train[0],  cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las imágenes vienen sin normalizar, por tanto lo primero será pasarlas del rango $[0,255]$ al rango $[-1,1]$ y luego crearemos los datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizar los datos al rango [-1, 1]\n",
        "x_train, x_test = (x_train / 127.5) - 1, (x_test / 127.5) - 1\n",
        "\n",
        "# Crear los datasets de tensorflow\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, x_train))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Arquitectura del modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Red Generadora**\n",
        "\n",
        "Esta red se encargará de transformar un vector de ruido Gaussiano en $\\mathbb{R}^{100}$ en una imagen de $1 \\times 28 \\times 28$. Para ello se aplicarán de forma consecutiva una serie de convoluciones transpuestas (deconvoluciones) que generarán el volumen deseado.\n",
        "\n",
        "> **NOTA:** Hay que tener en cuenta que la red generadora ha de crear imágenes en el mismo rango de valores que las imágenes reales. De no hacerlo, el discriminador tendría muy facil su tarea de detectar imágenes verdaderas y falsas.\n",
        "En este caso hemos normalizado las imágenes del conjunto MNIST en el rango $[0, 1]$, por tanto pondremos una función de activación *sigmoide* a la salida de nuestra red para obtener el mismo resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Red Discriminadora**\n",
        "\n",
        "La segunda red es la encargada de clasificar, dada una imagen de $1 \\times 28 \\times 28$, en verdadera o generada mediante clasificación binaria. Para ello aplicaremos de forma consecutiva una serie de convoluciones que irán transformando un volumen de activaciones en otro hasta llegar a una única neurona de salida.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_gan(learning_rate=1e-4):\n",
        "\n",
        "    # Definición del generador\n",
        "    input_tensor = layers.Input(shape=(100,))\n",
        "    x = layers.Dense(7*7*128)(input_tensor)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Reshape((7, 7, 128))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2DTranspose(1, kernel_size=3, padding='same', activation='tanh')(x)\n",
        "    generator = models.Model(inputs=input_tensor, outputs=x, name=\"generator\")\n",
        "\n",
        "    # Definición del discriminador\n",
        "    input_tensor = layers.Input(shape=(28, 28, 1))\n",
        "    x = layers.Conv2D(64, kernel_size=3, strides=2, padding='same')(input_tensor)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Conv2D(256, kernel_size=3, padding='same')(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    output_tensor = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    discriminator = models.Model(inputs=input_tensor, outputs=output_tensor, name=\"discriminator\")\n",
        "\n",
        "    return generator, discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenar GAN\n",
        "Finalmente ya solo quedaría la parte más compleja, entrenar el modelo.\n",
        "En este caso no podemos utilizar el método `fit` de Keras puesto que para cada batch tendremos que:\n",
        "\n",
        "1. *Entrenar el discriminador:*\n",
        "    * Se obtienen las predicciones del discriminador para los ejemplos del bath (los reales).\n",
        "    * Se generan tantos vectores de ruido en $\\mathbb{R}^{100}$ como ejemplos tenga el batch y se pasan por el generador **(congelando previamente sus pesos)**.\n",
        "    * Se obtiene la loss del discriminador a partir de las predicciones del mismo ante los ejemplos reales y los falsos.\n",
        "    * Optimizamos el discriminador.\n",
        "\n",
        "2. *Entrenar el generador:*\n",
        "    * Se generan nuevos vectores de ruido y se pasan por el generador. En este caso generamos $2*batch\\_size$ para que el generador y el discriminador se optimicen con el mismo número de ejemplos.\n",
        "    * Se obtiene la predicción del discriminador ante los ejemplos anteriores y su loss correspondiente forzando al discriminador a predecir 1.\n",
        "    * Optimizamos el generador.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora detallaremos los pasos a realizar para entrenar nuestro modelo. Antes vamos a crear una función que dibuje, tras cada época, 4 ejemplos utilizando el generador.\n",
        "\n",
        "La otra función que crearemos es `train_step`. En esta definimos los pasos a realizar para cada batch de entrenamiento de nuestro modelo.\n",
        "\n",
        "> **NOTA:** Esta función está decorada con `@tf.function`. Al hacerlo, TensorFlow compila todas las operaciones en un gráfico computacional y provoca que se ejecute mucho más rápido.\n",
        "\n",
        "Finalmente definimos hiperparámetros, creamos el modelo, los datasets, la función de perdida, los optimizadores y entrenamos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Función para mostrar imágenes\n",
        "def plot_generated_images(generator, noise):\n",
        "    num_images = noise.shape[0]\n",
        "    generated_images = generator(noise).numpy()\n",
        "\n",
        "    # Crear subgráficas\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(10, 2))\n",
        "    for i in range(num_images):\n",
        "        axes[i].imshow(generated_images[i].squeeze(), cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images, generator, discriminator, noise_dim, cross_entropy, discriminator_optimizer, generator_optimizer):\n",
        "    # Obtenemos el tamaño del batch actual (el último suele ser más pequeño)\n",
        "    current_batch_size = real_images.shape[0]\n",
        "    # Generar ruido aleatorio para crear imágenes falsas\n",
        "    noise = tf.random.normal([current_batch_size, noise_dim])\n",
        "    # Etiquetas para datos reales y generados\n",
        "    real_labels = tf.ones((current_batch_size, 1))\n",
        "    fake_labels = tf.zeros((current_batch_size, 1))\n",
        "\n",
        "    # Generar imágenes falsas utilizando el generador\n",
        "    generated_images = generator(noise) \n",
        "\n",
        "    # Entrenar el discriminador\n",
        "    # -------------------------------------------------------------------------------------\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "        # Obtenemos predicciones del discriminador para las imágenes reales y generadas\n",
        "        real_output = discriminator(real_images)\n",
        "        fake_output = discriminator(generated_images)\n",
        "        # Calcular la pérdida (loss) del discriminador para imágenes reales y generadas\n",
        "        disc_loss_real = cross_entropy(real_labels, real_output)\n",
        "        disc_loss_fake = cross_entropy(fake_labels, fake_output)       \n",
        "        # La pérdida total del discriminador es la suma de ambas pérdidas\n",
        "        disc_loss = disc_loss_real + disc_loss_fake\n",
        "\n",
        "    # Calcular los gradientes del discriminador con respecto a su pérdida\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    # Aplicar los gradientes al optimizador del discriminador\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    # Entrenar el generador\n",
        "    # -------------------------------------------------------------------------------------\n",
        "    \n",
        "    with tf.GradientTape() as gen_tape:\n",
        "        # Generar nuevas imágenes utilizando el ruido\n",
        "        generated_images = generator(noise)\n",
        "        # Obtener las predicciones del discriminador para las imágenes generadas\n",
        "        fake_output = discriminator(generated_images)\n",
        "        # Calcular la pérdida (loss) del generador usando las etiquetas reales\n",
        "        gen_loss = cross_entropy(real_labels, fake_output)\n",
        "\n",
        "    # Calcular los gradientes del generador con respecto a su pérdida\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    # Aplicar los gradientes al optimizador del generador\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    # Retornar las pérdidas del discriminador y del generador\n",
        "    return disc_loss, gen_loss\n",
        "\n",
        "# Configuración de parámetros \n",
        "noise_dim = 100\n",
        "batch_size = 64\n",
        "learning_rate = 0.0005\n",
        "num_epochs = 50\n",
        "\n",
        "# Crear y entrenar la GAN\n",
        "generator, discriminator = create_gan()\n",
        "\n",
        "# Definir los batches\n",
        "train_dataset = train_data.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_data.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Función de pérdida\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# Definir optimizadores\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
        "\n",
        "# Generamos 6 vectores de ruido para monitorizar el generador durante el entrenamiento\n",
        "plot_noise = tf.random.normal([6, noise_dim])\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for real_images, _ in train_dataset:\n",
        "        # Entrenar el modelo\n",
        "        disc_loss, gen_loss = train_step(real_images, generator, discriminator, noise_dim, cross_entropy, discriminator_optimizer, generator_optimizer)\n",
        "        \n",
        "    # Borrar la consola\n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    # Imprimir losses y gráfico\n",
        "    print(f'Epoch {epoch}, Discriminator Loss: {disc_loss.numpy():0.3f}, Generator Loss: {gen_loss.numpy():0.3f}')\n",
        "    plot_generated_images(generator, plot_noise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generación\n",
        "Para finalizar vamos a utilizar el generador para crear imágenes. En este caso vamos a crear imágenes asociadas a vectores de ruido $\\mathbb{R}^{100}$ con todo valores -1, con todo valores 1 y $n$ intermedios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir los valores para todos los elementos del vector de ruido\n",
        "values = tf.linspace(-1.0, 1.0, 10)  # 10 valores entre -1 y 1\n",
        "\n",
        "# Crear una figura para los resultados, una sola fila con 5 columnas\n",
        "fig, axes = plt.subplots(1, len(values), figsize=(15, 3))\n",
        "\n",
        "# Generar imágenes para cada valor en el vector de ruido\n",
        "for i, v in enumerate(values):\n",
        "    # Crear un vector de ruido donde todos los elementos son iguales al valor actual\n",
        "    noise = tf.fill([1, noise_dim], v)\n",
        "    # Generar una imagen con el generador\n",
        "    generated_image = generator(noise)\n",
        "    \n",
        "    # Plotear la imagen en la posición correcta de la cuadrícula\n",
        "    ax = axes[i]\n",
        "    ax.axis('off')\n",
        "    ax.imshow(tf.squeeze(generated_image), cmap='Greys_r')\n",
        "    ax.set_title(f'{v:.2f}', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
